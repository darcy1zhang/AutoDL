{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7af9c33-6209-4f51-9c91-4cce3c6350b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 116>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m test_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/simu_10000_0.1_141_178_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)[:,\u001b[38;5;241m1004\u001b[39m])\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m10000\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# print(test_labels.shape)\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m best_individual \u001b[38;5;241m=\u001b[39m \u001b[43mgenetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Output the selection result\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Individual:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_individual)\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mgenetic_algorithm\u001b[0;34m(train_data, test_data, num_features, hidden_size, output_size, population_size, generations, mutation_rate)\u001b[0m\n\u001b[1;32m     88\u001b[0m population \u001b[38;5;241m=\u001b[39m initialize_population(population_size, num_features)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generations):\n\u001b[0;32m---> 91\u001b[0m     fitness_scores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     parents \u001b[38;5;241m=\u001b[39m select_parents(population, fitness_scores)\n\u001b[1;32m     94\u001b[0m     new_population \u001b[38;5;241m=\u001b[39m []\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mevaluate_population\u001b[0;34m(population, train_data, test_data, num_features, hidden_size, output_size, epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m l1_regularization \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, requires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m---> 49\u001b[0m     l1_regularization \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(param, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l1_regularization \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.005\u001b[39m\n\u001b[1;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2*input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(2*input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def initialize_population(population_size, num_features):\n",
    "    return torch.randint(2, (population_size, num_features), dtype=torch.float32)\n",
    "\n",
    "def evaluate_population(population, train_data, test_data, num_features, hidden_size, output_size, epochs=10):\n",
    "    fitness_scores = []\n",
    "    for chromosome in population:\n",
    "        selected_features = torch.nonzero(chromosome).squeeze().tolist()\n",
    "        if not selected_features:\n",
    "            # prevent the case that none of the features is selected\n",
    "            fitness_scores.append(0)\n",
    "            continue\n",
    "\n",
    "        # select features\n",
    "        train_features = train_data[:, selected_features]\n",
    "        test_features = test_data[:, selected_features]\n",
    "\n",
    "        # train\n",
    "        if isinstance(selected_features,int):\n",
    "            MLP(1,hidden_size,output_size)\n",
    "        else:\n",
    "            model = MLP(len(selected_features), hidden_size, output_size)\n",
    "        criterion = nn.L1Loss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            outputs = model(train_features)\n",
    "            loss = criterion(outputs, train_labels)\n",
    "            l1_regularization = torch.tensor(0.0, requires_grad = True)\n",
    "            for param in model.parameters():\n",
    "                l1_regularization += torch.norm(param, p=1)\n",
    "            loss += l1_regularization * 0.005\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # test the selected feature\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(test_features)\n",
    "            _, predicted = torch.max(test_outputs.data, 1)\n",
    "            accuracy = (predicted == test_labels).sum().item() / len(test_labels)\n",
    "            fitness_scores.append(accuracy)\n",
    "\n",
    "    return np.array(fitness_scores)\n",
    "\n",
    "\n",
    "def select_parents(population, fitness_scores):\n",
    "    population_np = population.numpy()\n",
    "\n",
    "    sorted_indices = np.argsort(fitness_scores)[::-1]\n",
    "    selected_indices = sorted_indices[:2] \n",
    "\n",
    "    selected_parents = torch.from_numpy(population_np[selected_indices])\n",
    "\n",
    "    return selected_parents\n",
    "\n",
    "def crossover(parents):\n",
    "    crossover_point = torch.randint(1, parents.shape[1], (1,))\n",
    "    child1 = torch.cat((parents[0, :crossover_point], parents[1, crossover_point:]))\n",
    "    child2 = torch.cat((parents[1, :crossover_point], parents[0, crossover_point:]))\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(child, mutation_rate):\n",
    "    mutation_mask = (torch.rand(child.shape) < mutation_rate).float()\n",
    "    child = (child + mutation_mask) % 2\n",
    "    return child\n",
    "\n",
    "# main loop\n",
    "def genetic_algorithm(train_data, test_data, num_features, hidden_size, output_size, population_size=50, generations=50, mutation_rate=0.01):\n",
    "    population = initialize_population(population_size, num_features)\n",
    "\n",
    "    for generation in range(generations):\n",
    "        fitness_scores = evaluate_population(population, train_data, test_data, num_features, hidden_size, output_size)\n",
    "        parents = select_parents(population, fitness_scores)\n",
    "\n",
    "        new_population = []\n",
    "        for _ in range(population_size // 2):\n",
    "            child1, child2 = crossover(parents)\n",
    "            child1 = mutate(child1, mutation_rate)\n",
    "            child2 = mutate(child2, mutation_rate)\n",
    "            new_population.extend([child1, child2])\n",
    "\n",
    "        population = torch.stack(new_population)\n",
    "\n",
    "    best_individual_index = np.argmax(fitness_scores)\n",
    "    best_individual = population[best_individual_index]\n",
    "\n",
    "    return best_individual\n",
    "\n",
    "\n",
    "train_data = torch.from_numpy(np.load(\"../data/features_rand_train.npy\")).float()\n",
    "test_data = torch.from_numpy(np.load(\"../data/features_rand_test.npy\")).float()\n",
    "train_labels = torch.from_numpy(np.load(\"../data/simu_20000_0.1_90_140_train.npy\")[:,1004]).long().reshape(20000,1)\n",
    "test_labels = torch.from_numpy(np.load(\"../data/simu_10000_0.1_141_178_test.npy\")[:,1004]).long().reshape(10000,1)\n",
    "# print(test_labels.shape)\n",
    "\n",
    "\n",
    "best_individual = genetic_algorithm(train_data, test_data, num_features=11, hidden_size=8, output_size=1)\n",
    "\n",
    "# Output the selection result\n",
    "print(\"Best Individual:\", best_individual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
