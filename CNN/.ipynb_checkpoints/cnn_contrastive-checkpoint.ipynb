{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e75128b6-4ec0-497c-92cd-accb375e85a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.0 90.0\n",
      "S--epoch:0    MAE:-3606.191650390625   Pure:90.25111325073242   ConLoss:-3696.4427636413575\n",
      "epoch:0    MAE_test:63.2197939453125\n",
      "S--epoch:1    MAE:-3707.04303515625   Pure:52.60738534545899   ConLoss:-3759.650420501709\n",
      "epoch:1    MAE_test:54.9541863861084\n",
      "S--epoch:2    MAE:-3756.31166015625   Pure:24.052025741577147   ConLoss:-3780.363685897827\n",
      "epoch:2    MAE_test:25.33960775756836\n",
      "S--epoch:3    MAE:-3764.33809375   Pure:22.808102233886718   ConLoss:-3787.1461959838866\n",
      "epoch:3    MAE_test:24.470404296875\n",
      "S--epoch:4    MAE:-3749.70928515625   Pure:18.467624809265136   ConLoss:-3768.1769099655153\n",
      "epoch:4    MAE_test:15.379315963745118\n",
      "S--epoch:5    MAE:-3749.287046875   Pure:16.95445833206177   ConLoss:-3766.241505207062\n",
      "epoch:5    MAE_test:29.508266147613526\n",
      "S--epoch:6    MAE:-3757.807017578125   Pure:19.956457916259765   ConLoss:-3777.7634754943847\n",
      "epoch:6    MAE_test:25.512694931030275\n",
      "S--epoch:7    MAE:-3775.129232421875   Pure:18.4520532913208   ConLoss:-3793.581285713196\n",
      "epoch:7    MAE_test:19.67102207183838\n",
      "S--epoch:8    MAE:-3738.836916015625   Pure:20.1478803024292   ConLoss:-3758.984796318054\n",
      "epoch:8    MAE_test:20.742481254577637\n",
      "S--epoch:9    MAE:-3739.879095703125   Pure:18.473107681274413   ConLoss:-3758.352203384399\n",
      "epoch:9    MAE_test:21.831953567504883\n",
      "S--epoch:10    MAE:-3752.400029296875   Pure:17.515722152709962   ConLoss:-3769.915751449585\n",
      "epoch:10    MAE_test:32.80991030883789\n",
      "Test_epoch:10    MAE_test:32.80991030883789\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S--epoch:11    MAE:-3739.227990234375   Pure:17.765237815856935   ConLoss:-3756.993228050232\n",
      "epoch:11    MAE_test:20.271504150390626\n",
      "S--epoch:12    MAE:-3757.86533984375   Pure:17.848127914428712   ConLoss:-3775.713467758179\n",
      "epoch:12    MAE_test:25.67187934875488\n",
      "S--epoch:13    MAE:-3710.15475390625   Pure:20.19701374053955   ConLoss:-3730.3517676467895\n",
      "epoch:13    MAE_test:38.1838843460083\n",
      "S--epoch:14    MAE:-3721.63012109375   Pure:19.606680671691894   ConLoss:-3741.2368017654417\n",
      "epoch:14    MAE_test:19.699940658569336\n",
      "S--epoch:15    MAE:-3737.224853515625   Pure:18.63031726837158   ConLoss:-3755.8551707839965\n",
      "epoch:15    MAE_test:25.04617349243164\n",
      "S--epoch:16    MAE:-3590.908740234375   Pure:13.634353546142577   ConLoss:-3604.5430937805177\n",
      "epoch:16    MAE_test:12.832940864562989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     dis \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(features[i, :, :] \u001b[38;5;241m*\u001b[39m features[j, :, :]) \u001b[38;5;241m/\u001b[39m (\n\u001b[1;32m     56\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mnorm(features[i, :, :]) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(features[j, :, :]))\n\u001b[1;32m     57\u001b[0m     feature_dis\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mexp(dis))\n\u001b[0;32m---> 58\u001b[0m sorted_id_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msp_diff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msp_diff\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m sorted_feature_dis \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sorted_id_diff)):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from dataset import *\n",
    "from model import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_log = np.array([])\n",
    "test_log = np.array([])\n",
    "lambda_contrast = 2000\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "model = VGG_contrast().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "tmp = np.load(\"../data/simu_20000_0.1_90_140_train.npy\")\n",
    "max = np.max(tmp[:, 1004])\n",
    "min = np.min(tmp[:, 1004])\n",
    "print(max, min)\n",
    "\n",
    "train_dataset = Dataset(\"../data/simu_20000_0.1_90_140_train.npy\", 0, 0)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataset = Dataset(\"../data/simu_10000_0.1_90_140_resonance_morlet.npy\", 0, 1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "\n",
    "    loss_ERM_total = 0\n",
    "    step = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        output, features = model(data)\n",
    "        \n",
    "        loss_ERM = criterion(output, target)\n",
    "        loss_contrastive_total = 0\n",
    "        loss_ERM_total += loss_ERM.item()\n",
    "        \n",
    "        # if batch_idx%10:\n",
    "        #     print(\"%d\"%(batch_idx))\n",
    "\n",
    "        # for sp\n",
    "        sp_diff = []\n",
    "        feature_dis = []\n",
    "        sp_contrastive_loss = 0.0\n",
    "        sp_contrastive_loss = torch.tensor(sp_contrastive_loss, requires_grad=True)\n",
    "\n",
    "        for i in range(len(target[:, 0, 0]) - 1):\n",
    "            for j in range(i + 1, len(target[:, 0, 0])):\n",
    "                diff = torch.abs(target[i, 0, 0] - target[j, 0, 0])\n",
    "                sp_diff.append(diff)\n",
    "                dis = torch.sum(features[i, :, :] * features[j, :, :]) / (\n",
    "                            torch.norm(features[i, :, :]) * torch.norm(features[j, :, :]))\n",
    "                feature_dis.append(torch.exp(dis))\n",
    "            sorted_id_diff = sorted(range(len(sp_diff)), key=lambda k: sp_diff[k])\n",
    "\n",
    "            sorted_feature_dis = []\n",
    "            for k in range(len(sorted_id_diff)):\n",
    "                sorted_feature_dis.append(feature_dis[sorted_id_diff[k]])\n",
    "\n",
    "            temp_sp_loss = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "            for p in range(len(sorted_feature_dis) - 1):\n",
    "                sum = torch.tensor(0.0, requires_grad=True)\n",
    "                for q in range(p + 1, len(sorted_feature_dis)):\n",
    "                    sum = sum + sorted_feature_dis[q]\n",
    "                temp_sp_loss = temp_sp_loss + torch.log(sorted_feature_dis[p]) - torch.log(sum)\n",
    "            temp_sp_loss = temp_sp_loss / (len(sorted_feature_dis) - 1)\n",
    "\n",
    "            sp_contrastive_loss = sp_contrastive_loss + temp_sp_loss\n",
    "\n",
    "            sp_diff = sp_diff[:i + 1]\n",
    "\n",
    "            feature_dis = feature_dis[:i + 1]\n",
    "\n",
    "        sp_contrastive_loss = sp_contrastive_loss / (len(target[:, 0, 0]) - 1)\n",
    "\n",
    "        # print(loss)\n",
    "        # print(sp_contrastive_loss)\n",
    "        loss_contrastive_total += sp_contrastive_loss.item()\n",
    "\n",
    "        loss = loss_ERM + sp_contrastive_loss * lambda_contrast\n",
    "              \n",
    "        optimizer.zero_grad()\n",
    "        # sp_contrastive_loss.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_total = loss_total + loss.item()\n",
    "        step = step + 1\n",
    "\n",
    "    tmp = './pth/S_model_%d_%.4f.pth' % (epoch, loss_total/step)\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model, tmp)\n",
    "    print(\"S--epoch:\" + str(epoch) + \"    MAE:\" + str(loss_total/step) + \"   Pure:\" + str(loss_ERM_total/step) + \"   ConLoss:\"+ str((loss_total-loss_ERM_total)/step))\n",
    "    train_log = np.append(train_log, loss_total/step)\n",
    "\n",
    "    loss_test = 0\n",
    "    step = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output, features = model(data)\n",
    "\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            loss_test = loss_test + loss.item()\n",
    "            step = step + 1\n",
    "\n",
    "        loss_mean = loss_test / step\n",
    "        print(\"epoch:\" + str(epoch) + \"    MAE_test:\" + str(loss_mean))\n",
    "        test_log = np.append(test_log, loss_mean)\n",
    "    \n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        print(\"Test_epoch:\" + str(epoch) + \"    MAE_test:\" + str(loss_mean))\n",
    "        # tmp_epoch = np.arange(epoch+1)\n",
    "        # print(tmp_epoch)\n",
    "        # print(next(model.OneToOneLayer.parameters()))\n",
    "        plt.plot(train_log)\n",
    "        plt.plot(test_log)\n",
    "        plt.ylim(0,20)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
